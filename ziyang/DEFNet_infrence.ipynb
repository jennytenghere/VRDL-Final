{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c875f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:03.405589Z",
     "iopub.status.busy": "2025-05-19T03:29:03.405284Z",
     "iopub.status.idle": "2025-05-19T03:29:05.208421Z",
     "shell.execute_reply": "2025-05-19T03:29:05.207580Z"
    },
    "papermill": {
     "duration": 1.809185,
     "end_time": "2025-05-19T03:29:05.209969",
     "exception": false,
     "start_time": "2025-05-19T03:29:03.400784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best.pth']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "os.listdir(\"../input/dfnet6/pytorch/default/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1c6097",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:05.221612Z",
     "iopub.status.busy": "2025-05-19T03:29:05.221173Z",
     "iopub.status.idle": "2025-05-19T03:29:15.548783Z",
     "shell.execute_reply": "2025-05-19T03:29:15.547936Z"
    },
    "papermill": {
     "duration": 10.334981,
     "end_time": "2025-05-19T03:29:15.550327",
     "exception": false,
     "start_time": "2025-05-19T03:29:05.215346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "gc.collect()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class EnsembleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(EnsembleNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        vgg = models.vgg19(pretrained=False)\n",
    "        self.vgg = vgg.features\n",
    "\n",
    "        inception = models.inception_v3(pretrained=False, aux_logits=True)\n",
    "        inception.fc = nn.Identity()\n",
    "        self.inception = inception\n",
    "\n",
    "        resnet = models.resnet50(pretrained=False)\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-2])\n",
    "\n",
    "        densenet = models.densenet121(pretrained=False)\n",
    "        self.densenet = densenet.features\n",
    "\n",
    "        self.vgg_head = nn.Linear(512, num_classes)\n",
    "        self.google_head = nn.Linear(2048, num_classes)\n",
    "        self.resnet_head = nn.Linear(2048, num_classes)\n",
    "        self.dense_head = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.fusion_net = nn.Sequential(\n",
    "            nn.Linear(512 + 2048 + 2048 + 1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "        \n",
    "    def flatten(self, out):\n",
    "        return F.adaptive_avg_pool2d(out, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        vgg_feat = self.flatten(self.vgg(x))  # [B, 512, H/32, W/32]\n",
    "        inception_feat = self.inception(x)\n",
    "        if(self.training):\n",
    "            inception_feat =  inception_feat.logits\n",
    "        resnet_feat = self.flatten(self.resnet(x))  # [B, 2048, H/32, W/32]\n",
    "        dense_feat = self.flatten(self.densenet(x))  # [B, 1024, H/32, W/32]\n",
    "        \n",
    "        # print(vgg_feat.shape, inception_feat, resnet_feat.shape, dense_feat.shape)\n",
    "        fused_feat = torch.cat([vgg_feat, inception_feat, resnet_feat, dense_feat], dim=1)\n",
    "\n",
    "        vgg_out = self.vgg_head(vgg_feat)\n",
    "        google_out = self.google_head(inception_feat)\n",
    "        resnet_out = self.resnet_head(resnet_feat)\n",
    "        dense_out = self.dense_head(dense_feat)\n",
    "        fusion_out = self.fusion_net(fused_feat)\n",
    "\n",
    "        return [fusion_out, vgg_out, google_out, resnet_out, dense_out]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3ab4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:15.557075Z",
     "iopub.status.busy": "2025-05-19T03:29:15.556724Z",
     "iopub.status.idle": "2025-05-19T03:29:15.562382Z",
     "shell.execute_reply": "2025-05-19T03:29:15.561630Z"
    },
    "papermill": {
     "duration": 0.010147,
     "end_time": "2025-05-19T03:29:15.563500",
     "exception": false,
     "start_time": "2025-05-19T03:29:15.553353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path = \"../input/cassava-leaf-disease-classification\", transform = None):\n",
    "        data = pd.read_csv(path + \"/train.csv\")\n",
    "        self.images = [path+\"/train_images/\"+p for p in data[\"image_id\"]]\n",
    "        self.labels = [x for x in data[\"label\"]]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = self.transform(Image.open(img_path).convert(\"RGB\"))\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d32d278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:15.569681Z",
     "iopub.status.busy": "2025-05-19T03:29:15.569442Z",
     "iopub.status.idle": "2025-05-19T03:29:15.573176Z",
     "shell.execute_reply": "2025-05-19T03:29:15.572467Z"
    },
    "papermill": {
     "duration": 0.008124,
     "end_time": "2025-05-19T03:29:15.574363",
     "exception": false,
     "start_time": "2025-05-19T03:29:15.566239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9f0a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:15.581009Z",
     "iopub.status.busy": "2025-05-19T03:29:15.580506Z",
     "iopub.status.idle": "2025-05-19T03:29:15.601934Z",
     "shell.execute_reply": "2025-05-19T03:29:15.601109Z"
    },
    "papermill": {
     "duration": 0.02663,
     "end_time": "2025-05-19T03:29:15.603679",
     "exception": false,
     "start_time": "2025-05-19T03:29:15.577049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/cassava-leaf-disease-classification/\"\n",
    "image_path = path+\"test_images/\"\n",
    "used_models_keras = {\"DEFNet\":\"../input/dfnet10/pytorch/default/1/model12.pth\"}\n",
    "submission_df = pd.DataFrame(columns=[\"image_id\",\"label\"])\n",
    "submission_df[\"image_id\"] = os.listdir(image_path)\n",
    "submission_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478ebce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:15.610267Z",
     "iopub.status.busy": "2025-05-19T03:29:15.609982Z",
     "iopub.status.idle": "2025-05-19T03:29:24.462551Z",
     "shell.execute_reply": "2025-05-19T03:29:24.461791Z"
    },
    "papermill": {
     "duration": 8.857274,
     "end_time": "2025-05-19T03:29:24.463844",
     "exception": false,
     "start_time": "2025-05-19T03:29:15.606570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "onlykeras = False\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if cuda else 'cpu')\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),          \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def cut_crop_image(processed_img):\n",
    "    image = transform(processed_img)\n",
    "    return image.unsqueeze(0)\n",
    "\n",
    "def read_preprocess_file(img_path, normalize=False):\n",
    "    image = Image.open(img_path)\n",
    "    return (image.size[0], image.size[1]), image\n",
    "\n",
    "def multi_predict_tfhublayer(img_path, modelinstance):\n",
    "    img = cut_crop_image(read_preprocess_file(img_path, True)[1]).cuda()\n",
    "    total = modelinstance(img)\n",
    "    yhat = total[0].detach().cpu().numpy()\n",
    "    for i in range(1,len(total)):\n",
    "        yhat += total[i].detach().cpu().numpy()\n",
    "    return np.mean(yhat, axis=0)\n",
    "\n",
    "def predict_and_vote(image_list, modelinstances, onlykeras):\n",
    "    predictions = [] \n",
    "    with tqdm(total=len(image_list)) as process_bar:       \n",
    "      for img_path in image_list:\n",
    "        process_bar.update(1)  \n",
    "        Yhats = np.vstack([func(img_path, modelinstance) for func, modelinstance in modelinstances])\n",
    "        if onlykeras:\n",
    "            predictions.append(np.argmax(np.sum(Yhats, axis=0)))\n",
    "        else:\n",
    "            predictions.append(Yhats)    \n",
    "    return predictions\n",
    "\n",
    "inference_models = []\n",
    "\n",
    "if \"DEFNet\" in used_models_keras:\n",
    "    model = EnsembleNet(num_classes=5).to(device)\n",
    "    model_pth = used_models_keras[\"DEFNet\"]\n",
    "    model_pth = torch.load(model_pth, map_location=device)\n",
    "    model.load_state_dict(model_pth)\n",
    "    model.eval()\n",
    "    inference_models.append([multi_predict_tfhublayer, model])\n",
    "\n",
    "submission_df[\"label\"] = predict_and_vote([image_path+id for id in submission_df[\"image_id\"].values], inference_models, onlykeras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9920dc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:24.470900Z",
     "iopub.status.busy": "2025-05-19T03:29:24.470435Z",
     "iopub.status.idle": "2025-05-19T03:29:24.621965Z",
     "shell.execute_reply": "2025-05-19T03:29:24.621156Z"
    },
    "papermill": {
     "duration": 0.156694,
     "end_time": "2025-05-19T03:29:24.623628",
     "exception": false,
     "start_time": "2025-05-19T03:29:24.466934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id,label\r\n",
      "2216849948.jpg,4\r\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(submission_df[\"label\"])):\n",
    "    submission_df.loc[i,\"label\"] = np.argmax(submission_df[\"label\"][i][0], axis=0)\n",
    "submission_df[[\"image_id\",\"label\"]].to_csv(\"submission.csv\", index=False)\n",
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a7983b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:24.631434Z",
     "iopub.status.busy": "2025-05-19T03:29:24.630643Z",
     "iopub.status.idle": "2025-05-19T03:29:28.420105Z",
     "shell.execute_reply": "2025-05-19T03:29:28.419404Z"
    },
    "papermill": {
     "duration": 3.794714,
     "end_time": "2025-05-19T03:29:28.421487",
     "exception": false,
     "start_time": "2025-05-19T03:29:24.626773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EnsembleNet(num_classes=5).to(device)\n",
    "model_pth = used_models_keras[\"DEFNet\"]\n",
    "model_pth = torch.load(model_pth, map_location=device)\n",
    "model.load_state_dict(model_pth)\n",
    "model.eval()\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892b4e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:28.429543Z",
     "iopub.status.busy": "2025-05-19T03:29:28.428791Z",
     "iopub.status.idle": "2025-05-19T03:29:30.282996Z",
     "shell.execute_reply": "2025-05-19T03:29:30.282403Z"
    },
    "papermill": {
     "duration": 1.859577,
     "end_time": "2025-05-19T03:29:30.284406",
     "exception": false,
     "start_time": "2025-05-19T03:29:28.424829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "classes_name = ['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']\n",
    "\n",
    "def getConfusionMatrix(n_labels, n_predicts, class_names, title):\n",
    "    # 建立資料夾\n",
    "    folder_path = './matrix'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"資料夾 '{folder_path}' 已建立\")\n",
    "\n",
    "    # 計算 confusion matrix\n",
    "    cm = confusion_matrix(n_labels, n_predicts)\n",
    "\n",
    "    # 畫圖\n",
    "    plt.rcParams[\"font.size\"] = 16  # 全局字體大小（軸標籤等）\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))  # 可依類別數調整大小\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax, values_format='d')  # 'd' 表示整數格式\n",
    "    disp.im_.colorbar.remove()  # 若不想顯示 colorbar 可以移除\n",
    "\n",
    "    # 自訂軸標籤與標題大小\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=16)\n",
    "    ax.set_ylabel(\"True label\", fontsize=16)\n",
    "    ax.tick_params(labelsize=14)\n",
    "\n",
    "    # 放大每個 cell 的文字\n",
    "    for text in disp.text_.flat:\n",
    "        text.set_fontsize(18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{folder_path}/confusion_matrix.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5463a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:30.291677Z",
     "iopub.status.busy": "2025-05-19T03:29:30.291347Z",
     "iopub.status.idle": "2025-05-19T03:29:30.362615Z",
     "shell.execute_reply": "2025-05-19T03:29:30.361983Z"
    },
    "papermill": {
     "duration": 0.076299,
     "end_time": "2025-05-19T03:29:30.364004",
     "exception": false,
     "start_time": "2025-05-19T03:29:30.287705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"../input/cassava-leaf-disease-classification\"\n",
    "data = pd.read_csv(path + \"/train.csv\")\n",
    "fold = pd.read_csv(\"../input/cut-patch\" + \"/validation_data.csv\")\n",
    "data = pd.merge(data, fold, on='image_id')\n",
    "indexes = data[\"fold\"]==0\n",
    "data = data[indexes].reset_index(drop=True)\n",
    "images = [path+\"/train_images/\"+p for p in data[\"image_id\"]]\n",
    "labels = [x for x in data[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e569b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:29:30.371333Z",
     "iopub.status.busy": "2025-05-19T03:29:30.370892Z",
     "iopub.status.idle": "2025-05-19T03:34:55.179988Z",
     "shell.execute_reply": "2025-05-19T03:34:55.179317Z"
    },
    "papermill": {
     "duration": 324.814467,
     "end_time": "2025-05-19T03:34:55.181643",
     "exception": false,
     "start_time": "2025-05-19T03:29:30.367176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "n_predicts = []\n",
    "n_labels = labels\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(labels)):#\n",
    "        img_path = images[i]\n",
    "        image = torch.unsqueeze(transform(Image.open(img_path).convert(\"RGB\")), 0)\n",
    "        image= image.to(device)\n",
    "        outputs = model(image)\n",
    "        output = outputs[0]\n",
    "        for j in range(1,len(outputs)):\n",
    "            output = output + outputs[j]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        n_predicts.append(predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb45d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T03:34:55.189404Z",
     "iopub.status.busy": "2025-05-19T03:34:55.189079Z",
     "iopub.status.idle": "2025-05-19T03:34:55.515611Z",
     "shell.execute_reply": "2025-05-19T03:34:55.514970Z"
    },
    "papermill": {
     "duration": 0.331784,
     "end_time": "2025-05-19T03:34:55.516957",
     "exception": false,
     "start_time": "2025-05-19T03:34:55.185173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料夾 './matrix' 已建立\n"
     ]
    }
   ],
   "source": [
    "getConfusionMatrix(n_labels, n_predicts, classes_name, \"DEFNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100a4eb",
   "metadata": {
    "papermill": {
     "duration": 0.002921,
     "end_time": "2025-05-19T03:34:55.523112",
     "exception": false,
     "start_time": "2025-05-19T03:34:55.520191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1718836,
     "sourceId": 13836,
     "sourceType": "competition"
    },
    {
     "datasetId": 7405062,
     "sourceId": 11793002,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 341734,
     "modelInstanceId": 321125,
     "sourceId": 389863,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 342264,
     "modelInstanceId": 321659,
     "sourceId": 390541,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 343024,
     "modelInstanceId": 322331,
     "sourceId": 391471,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 344708,
     "modelInstanceId": 323917,
     "sourceId": 393730,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 344963,
     "modelInstanceId": 324172,
     "sourceId": 394152,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 359.486902,
   "end_time": "2025-05-19T03:34:58.440741",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-19T03:28:58.953839",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
