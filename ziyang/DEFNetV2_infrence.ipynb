{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13836,"databundleVersionId":1718836,"sourceType":"competition"},{"sourceId":11793002,"sourceType":"datasetVersion","datasetId":7405062},{"sourceId":389863,"sourceType":"modelInstanceVersion","modelInstanceId":321125,"modelId":341734},{"sourceId":390541,"sourceType":"modelInstanceVersion","modelInstanceId":321659,"modelId":342264},{"sourceId":391471,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":322331,"modelId":343024},{"sourceId":393730,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":323917,"modelId":344708},{"sourceId":394152,"sourceType":"modelInstanceVersion","modelInstanceId":324172,"modelId":344963},{"sourceId":411596,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":336056,"modelId":357065},{"sourceId":411637,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":336090,"modelId":357099}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom PIL import Image\nos.listdir(\"../input/defnet/pytorch/default/1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:22:55.824220Z","iopub.execute_input":"2025-05-25T14:22:55.825049Z","iopub.status.idle":"2025-05-25T14:22:55.830686Z","shell.execute_reply.started":"2025-05-25T14:22:55.825025Z","shell.execute_reply":"2025-05-25T14:22:55.829908Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['best.pth']"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"import gc\nimport torch\n\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()\ngc.collect()\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom timm import create_model\n\nclass EnsembleNet(nn.Module):\n    def __init__(self, num_classes=10, pretrained = False):\n        super(EnsembleNet, self).__init__()\n        self.num_classes = num_classes\n\n        vgg = create_model(\"vit_large_patch32_224.orig_in21k\", pretrained=pretrained, img_size=512)\n        self.vgg = vgg\n\n        inception = create_model('resnext101_32x8d', pretrained=pretrained)\n        inception = nn.Sequential(*list(inception.children())[:-1])\n        self.inception = inception\n\n        resnet = create_model('efficientnet_b5', pretrained=pretrained)\n        self.resnet = nn.Sequential(*list(resnet.children())[:-1])\n\n        densenet = create_model('mobilenetv3_large_100', pretrained=pretrained)\n        self.densenet = nn.Sequential(*list(densenet.children())[:-1])\n\n        swin = create_model('swin_large_patch4_window7_224', pretrained=pretrained,features_only=True,img_size=512)\n        self.swin = swin\n\n        self.vgg_head = nn.Linear(1024, num_classes)\n        self.google_head = nn.Linear(2048, num_classes)\n        self.resnet_head = nn.Linear(2048, num_classes)\n        self.dense_head = nn.Linear(1280, num_classes)\n        self.swin_head = nn.Linear(1536, num_classes)\n\n        self.fusion_net = nn.Sequential(\n            nn.Linear(1024 + 2048 + 2048 + 1280 + 1536, 1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, 1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024, num_classes)\n        )\n        \n    def flatten(self, out):\n        return F.adaptive_avg_pool2d(out, (1, 1)).squeeze(-1).squeeze(-1)\n\n    def forward(self, x):\n        vgg_feat = self.vgg(x)  # [B, 512, H/32, W/32]\n        inception_feat = self.inception(x)\n        resnet_feat = self.resnet(x)  # [B, 2048, H/32, W/32]\n        dense_feat = self.densenet(x)  # [B, 1024, H/32, W/32]\n        swin_feat = self.swin(x)[3].mean((1,2))\n        \n        # print(vgg_feat.shape, inception_feat.shape, resnet_feat.shape, dense_feat.shape)\n        fused_feat = torch.cat([vgg_feat, inception_feat, resnet_feat, dense_feat, swin_feat], dim=1)\n\n        vgg_out = self.vgg_head(vgg_feat)\n        google_out = self.google_head(inception_feat)\n        resnet_out = self.resnet_head(resnet_feat)\n        dense_out = self.dense_head(dense_feat)\n        fusion_out = self.fusion_net(fused_feat)\n        swin_out = self.swin_head(swin_feat)\n\n        return [fusion_out, vgg_out, google_out, resnet_out, dense_out, swin_out]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:22:55.831916Z","iopub.execute_input":"2025-05-25T14:22:55.832479Z","iopub.status.idle":"2025-05-25T14:22:56.288111Z","shell.execute_reply.started":"2025-05-25T14:22:55.832462Z","shell.execute_reply":"2025-05-25T14:22:56.287515Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nclass MyDataset(Dataset):\n    def __init__(self, path = \"../input/cassava-leaf-disease-classification\", transform = None):\n        data = pd.read_csv(path + \"/train.csv\")\n        self.images = [path+\"/train_images/\"+p for p in data[\"image_id\"]]\n        self.labels = [x for x in data[\"label\"]]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = self.transform(Image.open(img_path).convert(\"RGB\"))\n        return image, self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:22:56.288690Z","iopub.execute_input":"2025-05-25T14:22:56.288861Z","iopub.status.idle":"2025-05-25T14:22:56.294362Z","shell.execute_reply.started":"2025-05-25T14:22:56.288847Z","shell.execute_reply":"2025-05-25T14:22:56.293523Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import os\ncuda = torch.cuda.is_available()\ndevice = torch.device('cuda' if cuda else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:22:56.296185Z","iopub.execute_input":"2025-05-25T14:22:56.296431Z","iopub.status.idle":"2025-05-25T14:22:56.309076Z","shell.execute_reply.started":"2025-05-25T14:22:56.296416Z","shell.execute_reply":"2025-05-25T14:22:56.308465Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"path = \"/kaggle/input/cassava-leaf-disease-classification/\"\nimage_path = path+\"test_images/\"\nused_models_keras = {\"DEFNet\":\"../input/defnet2/pytorch/default/1/model15.pth\"}\nsubmission_df = pd.DataFrame(columns=[\"image_id\",\"label\"])\nsubmission_df[\"image_id\"] = os.listdir(image_path)\nsubmission_df[\"label\"] = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:22:56.309863Z","iopub.execute_input":"2025-05-25T14:22:56.310110Z","iopub.status.idle":"2025-05-25T14:22:56.324964Z","shell.execute_reply.started":"2025-05-25T14:22:56.310095Z","shell.execute_reply":"2025-05-25T14:22:56.324448Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"onlykeras = False\ncuda = torch.cuda.is_available()\ndevice = torch.device('cuda' if cuda else 'cpu')\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((512, 512)),          \n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ndef cut_crop_image(processed_img):\n    image = transform(processed_img)\n    return image.unsqueeze(0)\n\ndef read_preprocess_file(img_path, normalize=False):\n    image = Image.open(img_path)\n    return (image.size[0], image.size[1]), image\n\ndef multi_predict_tfhublayer(img_path, modelinstance):\n    img = cut_crop_image(read_preprocess_file(img_path, True)[1]).cuda()\n    total = modelinstance(img)\n    yhat = total[0].detach().cpu().numpy()\n    for i in range(1,len(total)):\n        yhat += total[i].detach().cpu().numpy()\n    return np.mean(yhat, axis=0)\n\ndef predict_and_vote(image_list, modelinstances, onlykeras):\n    predictions = [] \n    with tqdm(total=len(image_list)) as process_bar:       \n      for img_path in image_list:\n        process_bar.update(1)  \n        Yhats = np.vstack([func(img_path, modelinstance) for func, modelinstance in modelinstances])\n        if onlykeras:\n            predictions.append(np.argmax(np.sum(Yhats, axis=0)))\n        else:\n            predictions.append(Yhats)    \n    return predictions\n\ninference_models = []\n\nif \"DEFNet\" in used_models_keras:\n    model = EnsembleNet(num_classes=5).to(device)\n    model_pth = used_models_keras[\"DEFNet\"]\n    model_pth = torch.load(model_pth, map_location=device)\n    model.load_state_dict(model_pth)\n    model.eval()\n    inference_models.append([multi_predict_tfhublayer, model])\n\nsubmission_df[\"label\"] = predict_and_vote([image_path+id for id in submission_df[\"image_id\"].values], inference_models, onlykeras)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:22:56.325742Z","iopub.execute_input":"2025-05-25T14:22:56.326088Z","iopub.status.idle":"2025-05-25T14:23:20.395308Z","shell.execute_reply.started":"2025-05-25T14:22:56.326064Z","shell.execute_reply":"2025-05-25T14:23:20.394500Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"for i in range(len(submission_df[\"label\"])):\n    submission_df.loc[i,\"label\"] = np.argmax(submission_df[\"label\"][i][0], axis=0)\nsubmission_df[[\"image_id\",\"label\"]].to_csv(\"submission.csv\", index=False)\n!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:23:20.397823Z","iopub.execute_input":"2025-05-25T14:23:20.398250Z","iopub.status.idle":"2025-05-25T14:23:20.611966Z","shell.execute_reply.started":"2025-05-25T14:23:20.398225Z","shell.execute_reply":"2025-05-25T14:23:20.610981Z"}},"outputs":[{"name":"stdout","text":"image_id,label\n2216849948.jpg,4\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"model = EnsembleNet(num_classes=5).to(device)\nmodel_pth = used_models_keras[\"DEFNet\"]\nmodel_pth = torch.load(model_pth, map_location=device)\nmodel.load_state_dict(model_pth)\nmodel.eval()\n0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:23:20.613329Z","iopub.execute_input":"2025-05-25T14:23:20.613649Z","iopub.status.idle":"2025-05-25T14:23:33.031866Z","shell.execute_reply.started":"2025-05-25T14:23:20.613611Z","shell.execute_reply":"2025-05-25T14:23:33.031176Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport seaborn as sns\n\nclasses_name = ['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']\n\ndef getConfusionMatrix(n_labels, n_predicts, class_names, title):\n    # 建立資料夾\n    folder_path = './matrix'\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n        print(f\"資料夾 '{folder_path}' 已建立\")\n\n    # 計算 confusion matrix\n    cm = confusion_matrix(n_labels, n_predicts)\n\n    # 畫圖\n    plt.rcParams[\"font.size\"] = 16  # 全局字體大小（軸標籤等）\n    fig, ax = plt.subplots(figsize=(10, 8))  # 可依類別數調整大小\n\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    disp.plot(cmap=plt.cm.Blues, ax=ax, values_format='d')  # 'd' 表示整數格式\n    disp.im_.colorbar.remove()  # 若不想顯示 colorbar 可以移除\n\n    # 自訂軸標籤與標題大小\n    ax.set_title(title, fontsize=20)\n    ax.set_xlabel(\"Predicted label\", fontsize=16)\n    ax.set_ylabel(\"True label\", fontsize=16)\n    ax.tick_params(labelsize=14)\n\n    # 放大每個 cell 的文字\n    for text in disp.text_.flat:\n        text.set_fontsize(18)\n\n    plt.tight_layout()\n    plt.savefig(f\"{folder_path}/confusion_matrix.png\")\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:23:33.032628Z","iopub.execute_input":"2025-05-25T14:23:33.032851Z","iopub.status.idle":"2025-05-25T14:23:33.040021Z","shell.execute_reply.started":"2025-05-25T14:23:33.032827Z","shell.execute_reply":"2025-05-25T14:23:33.039335Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"path = \"../input/cassava-leaf-disease-classification\"\ndata = pd.read_csv(path + \"/train.csv\")\nfold = pd.read_csv(\"../input/cut-patch\" + \"/validation_data.csv\")\ndata = pd.merge(data, fold, on='image_id')\nindexes = data[\"fold\"]==0\ndata = data[indexes].reset_index(drop=True)\nimages = [path+\"/train_images/\"+p for p in data[\"image_id\"]]\nlabels = [x for x in data[\"label\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:23:33.041947Z","iopub.execute_input":"2025-05-25T14:23:33.042176Z","iopub.status.idle":"2025-05-25T14:23:33.103358Z","shell.execute_reply.started":"2025-05-25T14:23:33.042152Z","shell.execute_reply":"2025-05-25T14:23:33.102557Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# from PIL import Image\n# from torchvision import transforms\n\n# n_predicts = []\n# n_labels = labels\n\n# transform = transforms.Compose([\n#     transforms.Resize((512, 512)),\n#     transforms.ToTensor(),\n#     transforms.Normalize((0.5,), (0.5,))\n# ])\n\n# with torch.no_grad():\n#     for i in range(len(labels)):#\n#         img_path = images[i]\n#         image = torch.unsqueeze(transform(Image.open(img_path).convert(\"RGB\")), 0)\n#         image= image.to(device)\n#         outputs = model(image)\n#         output = outputs[0]\n#         for j in range(1,len(outputs)):\n#             output = output + outputs[j]\n#         _, predicted = torch.max(output, 1)\n#         n_predicts.append(predicted.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:23:33.104085Z","iopub.execute_input":"2025-05-25T14:23:33.104323Z","iopub.status.idle":"2025-05-25T14:23:33.108301Z","shell.execute_reply.started":"2025-05-25T14:23:33.104306Z","shell.execute_reply":"2025-05-25T14:23:33.107532Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# getConfusionMatrix(n_labels, n_predicts, classes_name, \"DEFNetV2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:23:33.109101Z","iopub.execute_input":"2025-05-25T14:23:33.109371Z","iopub.status.idle":"2025-05-25T14:23:33.126670Z","shell.execute_reply.started":"2025-05-25T14:23:33.109348Z","shell.execute_reply":"2025-05-25T14:23:33.125894Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}